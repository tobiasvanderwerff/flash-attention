{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, os, math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# from torch.utils.cpp_extension import load_inline\n",
    "from urllib.request import urlretrieve\n",
    "from pathlib import Path\n",
    "\n",
    "from util import load_cuda, load_cuda_inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(precision=2, linewidth=140)\n",
    "torch.set_printoptions(precision=2, linewidth=140, sci_mode=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CUDA Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.5\n"
     ]
    }
   ],
   "source": [
    "os.environ['CUDA_LAUNCH_BLOCKING']='1'\n",
    "\n",
    "device_props = torch.cuda.get_device_properties(0)\n",
    "os.environ['TORCH_CUDA_ARCH_LIST'] = f'{device_props.major}.{device_props.minor}'\n",
    "\n",
    "print(os.environ.get('TORCH_CUDA_ARCH_LIST'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext wurlitzer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vector sum kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sources = [\"vector_sum.cu\"]\n",
    "# module = load_cuda(sources, build_directory=\"./build\", verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The input conditions for extension module inline_ext have changed. Bumping to version 2 and re-building as inline_ext_v2...\n",
      "Detected CUDA files, patching ldflags\n",
      "Emitting ninja build file ./build/build.ninja...\n",
      "/opt/conda/envs/flash-attention/lib/python3.11/site-packages/torch/utils/cpp_extension.py:1964: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. \n",
      "If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].\n",
      "  warnings.warn(\n",
      "Building extension module inline_ext_v2...\n",
      "Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading extension module inline_ext_v2...\n"
     ]
    }
   ],
   "source": [
    "src_dir = Path(\"csrc\")\n",
    "cu_path =  src_dir/\"vector_sum.cu\"\n",
    "cpp_path = src_dir/\"vector_sum.cpp\"\n",
    "\n",
    "cuda_src = cu_path.read_text()\n",
    "cpp_src = cpp_path.read_text()\n",
    "\n",
    "module = load_cuda_inline(cuda_src, cpp_src, ['vector_sum'], verbose=True, build_directory='./build')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['vector_sum']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[o for o in dir(module) if o[0]!='_']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define test case\n",
    "if True:\n",
    "  # Test case 1\n",
    "  n = 200\n",
    "  torch.manual_seed(1)\n",
    "  inp = torch.randn(200)\n",
    "  inp = inp.contiguous().cuda()\n",
    "else:\n",
    "  # Test case 2\n",
    "  inp = torch.tensor([1., 2., 3., 4., 5., 6.])\n",
    "  inp = inp.contiguous().cuda()\n",
    "  n = inp.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 613 μs, sys: 39 μs, total: 652 μs\n",
      "Wall time: 661 μs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "sum_gpu = module.vector_sum(inp).cpu()\n",
    "# sum_gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8.53 ms, sys: 3.6 ms, total: 12.1 ms\n",
      "Wall time: 32.9 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "sum_true = inp.sum().cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-4.93) tensor([-4.93])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test for correctness\n",
    "print(sum_true, sum_gpu)\n",
    "torch.isclose(sum_true, sum_gpu).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(True)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Check correctness\n",
    "torch.isclose(torch.matmul(m1, m2), module.matmul(m1c, m2c).cpu(), atol=1e-4).all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matmul"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(1)\n",
    "m1 = torch.randn(1000,2000)\n",
    "m2 = torch.randn(2000,1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The input conditions for extension module inline_ext have changed. Bumping to version 2 and re-building as inline_ext_v2...\n",
      "Detected CUDA files, patching ldflags\n",
      "Emitting ninja build file ./build/build.ninja...\n",
      "Building extension module inline_ext_v2...\n",
      "Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading extension module inline_ext_v2...\n"
     ]
    }
   ],
   "source": [
    "src_dir = Path(\"csrc\")\n",
    "cu_path =  src_dir/\"attention.cu\"\n",
    "cpp_path = src_dir/\"attention.cpp\"\n",
    "funcs = [\"matmul\"]\n",
    "\n",
    "cuda_src = cu_path.read_text()\n",
    "cpp_src = cpp_path.read_text()\n",
    "\n",
    "module = load_cuda_inline(cuda_src, cpp_src, funcs, verbose=True, build_directory='./build')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "m1c,m2c = m1.contiguous().cuda(), m2.contiguous().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = module.matmul(m1c, m2c).cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(True)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check correctness\n",
    "torch.isclose(res, torch.matmul(m1, m2), atol=1e-3).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.37 s ± 16.2 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit -n 10 _= module.matmul(m1c, m2c).cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "583 ms ± 1.22 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit -n 10 _= torch.matmul(m1c, m2c).cpu()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
